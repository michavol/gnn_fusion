wandb: False
wandb_entity: deep-talk
wandb_project: GCN_Fusion

# Paths 
models_dir: ../../../models
individual_models_dir: ${models_dir}/individual_models/
experiment_models_dir: /fused_models/
hydra_base_dir: ""

dataset_dir: ../../../gnn_benchmarking/data/molecules/ # uncommment for ZINC
#dataset_dir: ../../../gnn_benchmarking/data/superpixels/ # uncommment for MNIST
dataset: '?' # filled in automatically

# Each experiment should specify this path to its folder, dummy folder if not specified
models_conf_dir: ../../../src/conf/models/fused_models/

# File names
vanilla_model_save_path: ${models_dir}/fused_models/vanilla_avg/vanilla.pkl
otFused_model_save_path: ${models_dir}/fused_models/ot_fusion/otFused.pkl

defaults:
  - _self_
  #- ot: config_ot
  - optimal_transport: emd
  - ground_cost_mlp: v_sidak
  - ground_cost_gcn: v_1
  - graph_cost: feature_lp
  # The first model in below list is the target one
  - models/individual_models:
      - GCN_ZINC_GPU-1_01h01m17s_on_Jan_02_2024 # GCN (ZINC) with batchnorm
      - GCN_ZINC_GPU-1_01h08m48s_on_Jan_02_2024 # GCN (ZINC) with batchnorm
#      - GCN_ZINC_GPU-1_19h03m35s_on_Jan_06_2024 # GCN (ZINC) without batchnorm
#      - GCN_ZINC_GPU-1_19h18m15s_on_Jan_06_2024 # GCN (ZINC) without batchnorm
#      - MLP_ZINC_GPU-1_16h54m39s_on_Jan_07_2024 # MLP (ZINC) with exactly the same size as GCN without batchnorm
#      - MLP_ZINC_GPU-1_16h57m50s_on_Jan_07_2024 # MLP (ZINC) with exactly the same size as GCN without batchnorm
#      - GCN_MNIST_GPU-1_11h04m16s_on_Jan_05_2024 # GCN (MNIST) with batchnorm
#      - GCN_MNIST_GPU-1_11h39m56s_on_Jan_05_2024 # GCN (MNIST) with batchnorm

# Take batch normalised activations
acts_from_bn: True
# Will vectorize the graphs and treat graph convnets as MLPs
fast_l2: True
# Takes GCN activations, ignoring neighbors
# Needs an extra change in PyTorch code and setting a flag in benchmarking: gcn_layer.py
take_single_vertex_acts: False
# Whether to save aligned models
save_aligned: True
# Set the seeds so that everything is deterministic
deterministic: True
# Weighting of the aligned models in case of two
ensemble_step: 0.5
# Activation or weight based alignment
geom_ensemble_type: wts # acts or wts
# Whether to update the activations after aligning the weights
update_acts: True
# Whether to compute the histogram based on weight importance
importance: False
# Whether to return a normalised histogram
unbalanced: True
# Whether to skip alignment of the last layer
skip_last_layer: True
# How to handle the last layer if it's skipped
skip_last_layer_type: average # or second
# Whether to enforce columns of the transport matrix to sum to 1
correction: True
# Whether to align the weight matrix based on the transport matrix from the previous layer
past_correction: True
# What is the width ration of the fused models
width_ratio: 1
# How many times OT-fusion with different samples should be performed
ot_fusions_per_model: 5
# batch_size * num_batches gives the fusion sample size
batch_size: 100
num_batches: 1
# How to scale the batch size for GW cost (due to the problem being computationally challenging)
gw_batch_scaling: 1
# Whether to print more debug information
debug: False
device: cpu
gpu_id: -1

# Fine tuning fused models
fine_tune: False
fine_tune_epochs: 40
fine_tune_save_step: 20
