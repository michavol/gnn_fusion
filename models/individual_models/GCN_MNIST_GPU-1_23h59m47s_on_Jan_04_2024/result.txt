Dataset: MNIST,
Model: GCN

params={'seed': 14, 'epochs': 100, 'batch_size': 128, 'init_lr': 0.001, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-05, 'weight_decay': 0, 'print_epoch_interval': 5, 'max_time': 12}

net_params={'device': device(type='cpu'), 'gated': False, 'in_dim': 3, 'in_dim_edge': 1, 'residual': False, 'hidden_dim': 146, 'out_dim': 146, 'n_classes': 10, 'n_heads': -1, 'L': 4, 'readout': 'sum', 'layer_norm': True, 'batch_norm': True, 'in_feat_dropout': 0.0, 'dropout': 0.0, 'edge_feat': False, 'self_loop': False, 'pseudo_dim_MoNet': -1, 'kernel': -1, 'n_mlp_GIN': -1, 'learn_eps_GIN': True, 'neighbor_aggr_GIN': 'sum', 'sage_aggregator': 'meanpool', 'data_mode': 'default', 'gnn_per_block': -1, 'embedding_dim': -1, 'pool_ratio': -1, 'linkpred': True, 'num_pool': 1, 'cat': False, 'batch_size': 128, 'radius': 2, 'avg_node_num': 71, 'depth_of_mlp': 2, 'assign_dim': -9600, 'gpu_id': -1, 'total_param': 101365}

GCNNet(
  (embedding_h): Linear(in_features=3, out_features=146, bias=True)
  (in_feat_dropout): Dropout(p=0.0, inplace=False)
  (layers): ModuleList(
    (0-3): 4 x GCNLayer(in_channels=146, out_channels=146, residual=False)
  )
  (MLP_layer): MLPReadout(
    (FC_layers): ModuleList(
      (0): Linear(in_features=146, out_features=73, bias=True)
      (1): Linear(in_features=73, out_features=36, bias=True)
      (2): Linear(in_features=36, out_features=10, bias=True)
    )
  )
)

Total Parameters: 101365


    FINAL RESULTS
TEST ACCURACY: 89.6200
TRAIN ACCURACY: 96.9891


    Convergence Time (Epochs): 99.0000
Total Time Taken: 0.7485 hrs
Average Time Per Epoch: 26.7942 s


